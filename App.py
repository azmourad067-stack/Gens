import streamlit as st
import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
import re
import json
from datetime import datetime, timedelta
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.figure_factory as ff

# ML Imports optimis√©s
from sklearn.ensemble import (RandomForestRegressor, GradientBoostingRegressor, 
                             ExtraTreesRegressor, VotingRegressor, BaggingRegressor)
from sklearn.linear_model import Ridge, ElasticNet, BayesianRidge
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler, RobustScaler, PolynomialFeatures
from sklearn.model_selection import (train_test_split, cross_val_score, 
                                   GridSearchCV, RandomizedSearchCV, TimeSeriesSplit)
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
import warnings
warnings.filterwarnings('ignore')

# Configuration Streamlit ultra-optimis√©e
st.set_page_config(
    page_title="üèá Analyseur Hippique IA Pro Max",
    page_icon="üèá",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS avanc√© avec animations
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600;700&display=swap');
    
    .main-header {
        font-family: 'Poppins', sans-serif;
        font-size: 3.5rem;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        margin-bottom: 2rem;
        animation: glow 2s ease-in-out infinite alternate;
    }
    
    @keyframes glow {
        from { text-shadow: 0 0 20px rgba(102, 126, 234, 0.5); }
        to { text-shadow: 0 0 30px rgba(118, 75, 162, 0.8); }
    }
    
    .metric-card-pro {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 15px;
        color: white;
        text-align: center;
        margin: 0.8rem 0;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1);
        transition: transform 0.3s ease;
    }
    
    .metric-card-pro:hover {
        transform: translateY(-5px);
        box-shadow: 0 15px 40px rgba(0,0,0,0.2);
    }
    
    .prediction-box-pro {
        border-left: 5px solid #f59e0b;
        padding: 1.5rem;
        background: linear-gradient(135deg, #fffbeb 0%, #fef3c7 100%);
        border-radius: 10px;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    
    .ml-confidence-high { border-left-color: #10b981; background: linear-gradient(135deg, #ecfdf5 0%, #d1fae5 100%); }
    .ml-confidence-medium { border-left-color: #f59e0b; background: linear-gradient(135deg, #fffbeb 0%, #fef3c7 100%); }
    .ml-confidence-low { border-left-color: #ef4444; background: linear-gradient(135deg, #fef2f2 0%, #fecaca 100%); }
    
    .feature-importance-bar {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        height: 8px;
        border-radius: 4px;
        margin: 5px 0;
    }
    
    .stProgress > div > div > div {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
    }
</style>
""", unsafe_allow_html=True)

# Configuration avanc√©e par type de course
ADVANCED_CONFIGS = {
    "PLAT": {
        "description": "üèÉ Course de galop - Analyse compl√®te handicap",
        "optimal_draws": [1, 2, 3, 4],
        "weight_importance": 0.35,
        "draw_importance": 0.25,
        "form_importance": 0.40,
        "distance_factors": {"sprint": 1.2, "mile": 1.0, "long": 0.8},
        "track_conditions": {"firm": 1.0, "good": 0.95, "soft": 0.85, "heavy": 0.75}
    },
    "ATTELE_AUTOSTART": {
        "description": "üöó Trot attel√© autostart - Strat√©gie optimis√©e",
        "optimal_draws": [4, 5, 6],
        "weight_importance": 0.10,
        "draw_importance": 0.30,
        "form_importance": 0.60,
        "autostart_bonuses": {1: -0.3, 2: -0.2, 3: -0.1, 4: 0.3, 5: 0.3, 6: 0.3, 7: 0.1, 8: 0.0}
    },
    "ATTELE_VOLTE": {
        "description": "üîÑ Trot attel√© volt√© - Focus performance pure",
        "optimal_draws": [],
        "weight_importance": 0.05,
        "draw_importance": 0.05,
        "form_importance": 0.90,
        "driver_importance": 0.25
    }
}

@st.cache_resource
class AdvancedHorseRacingML:
    """Syst√®me ML ultra-avanc√© pour analyse hippique"""
    
    def __init__(self):
        # Ensemble de mod√®les optimis√©s
        self.base_models = {
            'random_forest': RandomForestRegressor(
                n_estimators=200, max_depth=15, min_samples_split=3,
                min_samples_leaf=2, random_state=42, n_jobs=-1
            ),
            'gradient_boosting': GradientBoostingRegressor(
                n_estimators=150, learning_rate=0.1, max_depth=8,
                min_samples_split=3, random_state=42
            ),
            'extra_trees': ExtraTreesRegressor(
                n_estimators=150, max_depth=12, min_samples_split=2,
                random_state=42, n_jobs=-1
            ),
            'ridge': Ridge(alpha=1.0),
            'elastic_net': ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42),
            'bayesian_ridge': BayesianRidge(),
            'mlp': MLPRegressor(
                hidden_layer_sizes=(100, 50, 25), max_iter=1000,
                random_state=42, early_stopping=True
            )
        }
        
        # Ensemble voting
        self.ensemble_model = VotingRegressor([
            ('rf', self.base_models['random_forest']),
            ('gb', self.base_models['gradient_boosting']),
            ('et', self.base_models['extra_trees'])
        ])
        
        # Outils de preprocessing
        self.scalers = {
            'standard': StandardScaler(),
            'robust': RobustScaler()
        }
        self.poly_features = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)
        self.feature_selector = SelectKBest(score_func=f_regression, k=15)
        self.pca = PCA(n_components=0.95)
        self.kmeans = KMeans(n_clusters=3, random_state=42)
        
        # M√©triques et r√©sultats
        self.feature_importance = {}
        self.model_scores = {}
        self.prediction_confidence = {}
        self.is_trained = False
        
    def create_advanced_features(self, df, race_type):
        """Cr√©ation de features ultra-avanc√©es"""
        features = pd.DataFrame(index=df.index)
        
        # === FEATURES DE BASE OPTIMIS√âES ===
        features['odds_log'] = np.log1p(df['odds_numeric'])
        features['odds_inv'] = 1 / (df['odds_numeric'] + 0.01)
        features['odds_sqrt'] = np.sqrt(df['odds_numeric'])
        features['odds_power'] = np.power(df['odds_numeric'], 0.5)
        
        features['draw'] = df['draw_numeric']
        features['draw_log'] = np.log1p(df['draw_numeric'])
        features['draw_sqrt'] = np.sqrt(df['draw_numeric'])
        
        features['weight'] = df['weight_kg']
        features['weight_norm'] = (df['weight_kg'] - df['weight_kg'].mean()) / (df['weight_kg'].std() + 1e-8)
        features['weight_rank'] = df['weight_kg'].rank(pct=True)
        
        # === FEATURES D'√ÇGE ET SEXE ===
        if '√Çge/Sexe' in df.columns:
            features['age'] = df['√Çge/Sexe'].str.extract('(\d+)').astype(float).fillna(4)
            features['age_squared'] = features['age'] ** 2
            features['age_optimal'] = np.abs(features['age'] - 5)  # √Çge optimal ~5 ans
            
            features['is_mare'] = df['√Çge/Sexe'].str.contains('F', na=False).astype(int)
            features['is_horse'] = df['√Çge/Sexe'].str.contains('H', na=False).astype(int)
            features['is_gelding'] = df['√Çge/Sexe'].str.contains('M', na=False).astype(int)
        else:
            features['age'] = 4.0
            features['age_squared'] = 16.0
            features['age_optimal'] = 1.0
            features['is_mare'] = 0
            features['is_horse'] = 0
            features['is_gelding'] = 1
        
        # === ANALYSE AVANC√âE DE LA FORME ===
        if 'Musique' in df.columns:
            for i, row in df.iterrows():
                musique = str(row['Musique']) if pd.notna(row['Musique']) else ""
                positions = [int(c) for c in musique if c.isdigit() and int(c) <= 20]
                
                if positions:
                    # Statistiques de base
                    features.loc[i, 'form_avg'] = np.mean(positions)
                    features.loc[i, 'form_best'] = min(positions)
                    features.loc[i, 'form_worst'] = max(positions)
                    features.loc[i, 'form_std'] = np.std(positions) if len(positions) > 1 else 0
                    
                    # Analyse de tendance
                    if len(positions) >= 3:
                        recent_positions = positions[:3]
                        features.loc[i, 'form_trend'] = np.polyfit(range(len(recent_positions)), recent_positions, 1)[0]
                        features.loc[i, 'form_acceleration'] = np.mean(np.diff(recent_positions))
                    
                    # Constance et r√©gularit√©
                    features.loc[i, 'form_consistency'] = 1 / (1 + np.std(positions))
                    features.loc[i, 'form_recent_improvement'] = max(0, positions[-1] - np.mean(positions[:3])) if len(positions) >= 4 else 0
                    
                    # Victoires et places
                    features.loc[i, 'wins_total'] = positions.count(1)
                    features.loc[i, 'places_total'] = sum(1 for p in positions if p <= 3)
                    features.loc[i, 'wins_recent'] = positions[:3].count(1)
                    features.loc[i, 'places_recent'] = sum(1 for p in positions[:3] if p <= 3)
                    
                    # S√©ries et streaks
                    win_streak = 0
                    place_streak = 0
                    for p in positions:
                        if p == 1:
                            win_streak += 1
                        else:
                            break
                    for p in positions:
                        if p <= 3:
                            place_streak += 1
                        else:
                            break
                    features.loc[i, 'win_streak'] = win_streak
                    features.loc[i, 'place_streak'] = place_streak
                    
                    # Performance dans diff√©rentes conditions
                    features.loc[i, 'big_field_performance'] = np.mean([p for p in positions if p <= 16])  # Gros pelotons
                    features.loc[i, 'small_field_performance'] = np.mean([p for p in positions if p <= 8])   # Petits pelotons
        
        # Valeurs par d√©faut si pas de musique
        form_cols = ['form_avg', 'form_best', 'form_worst', 'form_std', 'form_trend', 'form_acceleration',
                    'form_consistency', 'form_recent_improvement', 'wins_total', 'places_total',
                    'wins_recent', 'places_recent', 'win_streak', 'place_streak',
                    'big_field_performance', 'small_field_performance']
        for col in form_cols:
            if col not in features.columns:
                features[col] = 0
        
        # === FEATURES RELATIVES ET COMPARATIVES ===
        features['odds_rank'] = df['odds_numeric'].rank()
        features['odds_percentile'] = df['odds_numeric'].rank(pct=True)
        features['weight_rank'] = df['weight_kg'].rank()
        features['draw_percentile'] = df['draw_numeric'].rank(pct=True)
        
        # √âcarts √† la moyenne
        features['odds_vs_avg'] = df['odds_numeric'] - df['odds_numeric'].mean()
        features['weight_vs_avg'] = df['weight_kg'] - df['weight_kg'].mean()
        features['draw_vs_avg'] = df['draw_numeric'] - df['draw_numeric'].mean()
        
        # === INTERACTIONS COMPLEXES ===
        features['odds_weight_ratio'] = features['odds_inv'] * features['weight_norm']
        features['draw_odds_interaction'] = features['draw'] * features['odds_log']
        features['age_form_interaction'] = features['age'] * features['form_consistency']
        features['weight_draw_penalty'] = features['weight'] * np.maximum(0, features['draw'] - 8)
        
        # === FEATURES SP√âCIFIQUES PAR TYPE ===
        config = ADVANCED_CONFIGS[race_type]
        
        if race_type == "PLAT":
            # Avantages/p√©nalit√©s corde pour le plat
            features['inner_draw_bonus'] = np.where(features['draw'] <= 4, 0.3, 0)
            features['outer_draw_penalty'] = np.where(features['draw'] >= 12, -0.2, 0)
            features['draw_optimal_distance'] = np.abs(features['draw'] - 4)
            
            # P√©nalit√©s poids sophistiqu√©es
            weight_baseline = df['weight_kg'].median()
            features['weight_penalty_linear'] = np.maximum(0, features['weight'] - weight_baseline) * 0.02
            features['weight_penalty_exponential'] = np.power(np.maximum(0, features['weight'] - weight_baseline), 1.5) * 0.01
            
        elif race_type == "ATTELE_AUTOSTART":
            # Strat√©gie autostart avanc√©e
            autostart_bonuses = config.get('autostart_bonuses', {})
            features['autostart_position_bonus'] = features['draw'].apply(lambda x: autostart_bonuses.get(x, 0))
            features['first_line_advantage'] = np.where(features['draw'] <= 9, 0.2, -0.1)
            features['center_first_line'] = np.where(features['draw'].isin([4, 5, 6]), 0.4, 0)
            
        elif race_type == "ATTELE_VOLTE":
            # Pour le volt√©, focus sur la forme pure
            features['pure_form_score'] = (features['form_consistency'] * 0.4 + 
                                         features['wins_recent'] * 0.3 + 
                                         features['places_recent'] * 0.3)
        
        # === CLUSTERING ET FEATURES AVANC√âES ===
        # Cr√©ation de profils de chevaux
        base_features_for_clustering = ['odds_inv', 'form_avg', 'age', 'weight_norm']
        if len(df) >= 3:
            cluster_data = features[base_features_for_clustering].fillna(0)
            try:
                clusters = self.kmeans.fit_predict(cluster_data)
                features['horse_profile_cluster'] = clusters
                features['cluster_0'] = (clusters == 0).astype(int)
                features['cluster_1'] = (clusters == 1).astype(int) 
                features['cluster_2'] = (clusters == 2).astype(int)
            except:
                features['horse_profile_cluster'] = 0
                features['cluster_0'] = 0
                features['cluster_1'] = 0
                features['cluster_2'] = 0
        
        # === FEATURES TEMPORELLES ET SAISONNI√àRES ===
        current_date = datetime.now()
        features['month'] = current_date.month
        features['season'] = (current_date.month % 12 + 3) // 3  # 1=hiver, 2=printemps, etc.
        features['is_weekend'] = current_date.weekday() >= 5
        
        return features.fillna(0)
    
    def optimize_hyperparameters(self, X, y, model_name='random_forest'):
        """Optimisation avanc√©e des hyperparam√®tres"""
        param_grids = {
            'random_forest': {
                'n_estimators': [100, 150, 200],
                'max_depth': [10, 15, 20],
                'min_samples_split': [2, 3, 5],
                'min_samples_leaf': [1, 2, 3]
            },
            'gradient_boosting': {
                'n_estimators': [100, 150],
                'learning_rate': [0.05, 0.1, 0.15],
                'max_depth': [6, 8, 10],
                'min_samples_split': [2, 3, 5]
            }
        }
        
        if model_name in param_grids and len(X) >= 20:
            base_model = self.base_models[model_name].__class__()
            
            # Utilisation de RandomizedSearchCV pour plus d'efficacit√©
            random_search = RandomizedSearchCV(
                base_model, param_grids[model_name],
                n_iter=20, cv=3, scoring='neg_mean_squared_error',
                random_state=42, n_jobs=-1
            )
            
            try:
                random_search.fit(X, y)
                return random_search.best_estimator_
            except:
                return self.base_models[model_name]
        
        return self.base_models[model_name]
    
    def train_advanced_models(self, X, y, optimize_hyperparams=True, use_feature_selection=True):
        """Entra√Ænement avanc√© avec s√©lection de features et optimisation"""
        
        if len(X) < 5:
            st.warning("‚ö†Ô∏è Pas assez de donn√©es pour entra√Ænement avanc√©")
            return {}
        
        # === PREPROCESSING AVANC√â ===
        X_processed = X.copy()
        
        # Normalisation robuste
        X_scaled = self.scalers['robust'].fit_transform(X_processed)
        
        # S√©lection de features si demand√©e
        if use_feature_selection and len(X.columns) > 10:
            try:
                X_selected = self.feature_selector.fit_transform(X_scaled, y)
                selected_features = self.feature_selector.get_support()
                selected_feature_names = X.columns[selected_features].tolist()
                st.info(f"üéØ {len(selected_feature_names)} features s√©lectionn√©es sur {len(X.columns)}")
            except:
                X_selected = X_scaled
                selected_feature_names = X.columns.tolist()
        else:
            X_selected = X_scaled
            selected_feature_names = X.columns.tolist()
        
        # Cr√©ation de features polynomiales si dataset pas trop grand
        if len(X.columns) <= 15 and len(X) >= 10:
            try:
                X_poly = self.poly_features.fit_transform(X_selected)
                X_final = X_poly
                feature_names_final = self.poly_features.get_feature_names_out(selected_feature_names)
            except:
                X_final = X_selected
                feature_names_final = selected_feature_names
        else:
            X_final = X_selected
            feature_names_final = selected_feature_names
        
        # === ENTRA√éNEMENT DES MOD√àLES ===
        results = {}
        
        # Division train/validation si assez de donn√©es
        if len(X) >= 10:
            X_train, X_val, y_train, y_val = train_test_split(
                X_final, y, test_size=0.3, random_state=42
            )
        else:
            X_train, X_val, y_train, y_val = X_final, X_final, y, y
        
        # Entra√Ænement de chaque mod√®le
        for name, model in self.base_models.items():
            try:
                # Optimisation des hyperparam√®tres si demand√©e
                if optimize_hyperparams and name in ['random_forest', 'gradient_boosting']:
                    optimized_model = self.optimize_hyperparameters(X_train, y_train, name)
                else:
                    optimized_model = model
                
                # Entra√Ænement
                optimized_model.fit(X_train, y_train)
                
                # Pr√©dictions
                y_pred_train = optimized_model.predict(X_train)
                y_pred_val = optimized_model.predict(X_val)
                
                # M√©triques
                results[name] = {
                    'model': optimized_model,
                    'train_r2': r2_score(y_train, y_pred_train),
                    'val_r2': r2_score(y_val, y_pred_val),
                    'train_mse': mean_squared_error(y_train, y_pred_train),
                    'val_mse': mean_squared_error(y_val, y_pred_val),
                    'train_mae': mean_absolute_error(y_train, y_pred_train),
                    'val_mae': mean_absolute_error(y_val, y_pred_val)
                }
                
                # Cross-validation si assez de donn√©es
                if len(X) >= 15:
                    cv_scores = cross_val_score(optimized_model, X_final, y, cv=3, scoring='r2')
                    results[name]['cv_r2_mean'] = cv_scores.mean()
                    results[name]['cv_r2_std'] = cv_scores.std()
                
                # Feature importance
                if hasattr(optimized_model, 'feature_importances_'):
                    importance_dict = dict(zip(feature_names_final, optimized_model.feature_importances_))
                    # Garder seulement les top features
                    sorted_importance = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)
                    results[name]['feature_importance'] = dict(sorted_importance[:15])
                    self.feature_importance[name] = results[name]['feature_importance']
                
                # Pr√©dictions finales sur tout le dataset
                final_predictions = optimized_model.predict(X_final)
                results[name]['predictions'] = final_predictions
                
                # Confiance des pr√©dictions (√©cart-type des pr√©dictions des arbres pour RF)
                if name == 'random_forest' and hasattr(optimized_model, 'estimators_'):
                    tree_predictions = np.array([tree.predict(X_final) for tree in optimized_model.estimators_])
                    prediction_std = np.std(tree_predictions, axis=0)
                    results[name]['prediction_confidence'] = 1 / (1 + prediction_std)  # Plus l'√©cart-type est faible, plus la confiance est √©lev√©e
                
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erreur entra√Ænement {name}: {str(e)}")
                continue
        
        # === MOD√àLE D'ENSEMBLE ===
        if len(results) >= 2:
            try:
                # S√©lection des meilleurs mod√®les pour l'ensemble
                best_models = sorted(results.items(), key=lambda x: x[1].get('val_r2', 0), reverse=True)[:3]
                
                ensemble_estimators = [(name, result['model']) for name, result in best_models]
                ensemble = VotingRegressor(ensemble_estimators)
                ensemble.fit(X_final, y)
                
                # M√©triques ensemble
                y_pred_ensemble = ensemble.predict(X_final)
                results['ensemble'] = {
                    'model': ensemble,
                    'r2': r2_score(y, y_pred_ensemble),
                    'mse': mean_squared_error(y, y_pred_ensemble),
                    'mae': mean_absolute_error(y, y_pred_ensemble),
                    'predictions': y_pred_ensemble,
                    'component_models': [name for name, _ in best_models]
                }
                
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erreur ensemble: {str(e)}")
        
        self.model_scores = results
        self.is_trained = True
        
        return results
    
    def get_best_model_predictions(self, results):
        """S√©lectionne le meilleur mod√®le et retourne ses pr√©dictions"""
        if not results:
            return np.array([]), "no_model"
        
        # Priorit√© √† l'ensemble s'il existe
        if 'ensemble' in results:
            return results['ensemble']['predictions'], 'ensemble'
        
        # Sinon, meilleur mod√®le bas√© sur R¬≤
        best_model_name = max(results.keys(), key=lambda x: results[x].get('val_r2', results[x].get('r2', 0)))
        return results[best_model_name]['predictions'], best_model_name
    
    def generate_prediction_report(self, results):
        """G√©n√®re un rapport d√©taill√© des pr√©dictions"""
        if not results:
            return "Aucun mod√®le entra√Æn√©"
        
        report = ["ü§ñ **RAPPORT D'ANALYSE ML AVANC√âE**", "="*50]
        
        # R√©sum√© des mod√®les
        report.append(f"\nüìä **Mod√®les entra√Æn√©s**: {len(results)}")
        
        for name, result in results.items():
            if name == 'ensemble':
                report.append(f"\nüéØ **{name.upper()}** (Meilleurs mod√®les combin√©s)")
                report.append(f"   ‚Ä¢ Composants: {', '.join(result.get('component_models', []))}")
            else:
                report.append(f"\nüîß **{name.upper()}**")
            
            report.append(f"   ‚Ä¢ R¬≤ Score: {result.get('val_r2', result.get('r2', 0)):.3f}")
            report.append(f"   ‚Ä¢ MSE: {result.get('val_mse', result.get('mse', 0)):.3f}")
            
            if 'cv_r2_mean' in result:
                report.append(f"   ‚Ä¢ CV R¬≤ (mean¬±std): {result['cv_r2_mean']:.3f}¬±{result['cv_r2_std']:.3f}")
        
        # Meilleur mod√®le
        best_predictions, best_model = self.get_best_model_predictions(results)
        report.append(f"\nüèÜ **Meilleur mod√®le s√©lectionn√©**: {best_model.upper()}")
        
        return "\n".join(report)

def create_advanced_visualizations(df_ranked, ml_results=None, prediction_confidence=None):
    """Visualisations ultra-avanc√©es avec m√©triques ML"""
    
    # Configuration des sous-graphiques
    fig = make_subplots(
        rows=3, cols=2,
        subplot_titles=(
            'üèÜ Scores ML avec Intervalles de Confiance',
            'üìä Distribution des Cotes (Histogramme + Densit√©)',
            'üéØ Corr√©lation Poids-Performance-√Çge',
            'üß† Top Features ML par Importance',
            'üìà Analyse de Forme vs Pr√©diction ML',
            'üîÑ Matrice de Corr√©lation des Facteurs'
        ),
        specs=[
            [{"secondary_y": True}, {"type": "histogram"}],
            [{"type": "scatter"}, {"type": "bar"}],
            [{"type": "scatter"}, {"type": "heatmap"}]
        ]
    )
    
    colors = px.colors.qualitative.Set3
    score_col = 'score_final' if 'score_final' in df_ranked.columns else 'ml_score'
    
    # Graphique 1: Scores avec intervalles de confiance
    if score_col in df_ranked.columns:
        y_values = df_ranked[score_col]
        
        # Intervalles de confiance si disponibles
        if prediction_confidence is not None:
            confidence = prediction_confidence if len(prediction_confidence) == len(df_ranked) else [0.5] * len(df_ranked)
            y_upper = y_values + np.array(confidence) * 0.1
            y_lower = y_values - np.array(confidence) * 0.1
            
            # Zone de confiance
            fig.add_trace(
                go.Scatter(
                    x=list(df_ranked['rang']) + list(df_ranked['rang'][::-1]),
                    y=list(y_upper) + list(y_lower[::-1]),
                    fill='toself',
                    fillcolor='rgba(102, 126, 234, 0.2)',
                    line=dict(color='rgba(255,255,255,0)'),
                    name='Intervalle Confiance',
                    showlegend=True
                ), row=1, col=1
            )
        
        # Scores principaux
        fig.add_trace(
            go.Scatter(
                x=df_ranked['rang'],
                y=y_values,
                mode='markers+lines',
                marker=dict(
                    size=15,
                    color=df_ranked['odds_numeric'],
                    colorscale='Viridis',
                    showscale=True,
                    colorbar=dict(title="Cote", x=0.45)
                ),
                text=[f"{row['Nom']}<br>Cote: {row['Cote']}<br>Score: {row[score_col]:.3f}" 
                      for _, row in df_ranked.iterrows()],
                hovertemplate='%{text}<extra></extra>',
                name='Score ML',
                line=dict(width=3, color=colors[0])
            ), row=1, col=1
        )
    
    # Graphique 2: Distribution avanc√©e des cotes
    fig.add_trace(
        go.Histogram(
            x=df_ranked['odds_numeric'],
            nbinsx=12,
            marker_color=colors[1],
            opacity=0.7,
            name='Distribution Cotes',
            yaxis='y2'
        ), row=1, col=2
    )
    
    # Ajout courbe de densit√©
    try:
        from scipy import stats
        density = stats.gaussian_kde(df_ranked['odds_numeric'])
        x_range = np.linspace(df_ranked['odds_numeric'].min(), df_ranked['odds_numeric'].max(), 100)
        fig.add_trace(
            go.Scatter(
                x=x_range,
                y=density(x_range),
                mode='lines',
                name='Densit√©',
                line=dict(color='red', width=2),
                yaxis='y2'
            ), row=1, col=2
        )
    except:
        pass
    
    # Graphique 3: Analyse 3D (Poids-Performance-√Çge)
    if 'age' in df_ranked.columns and score_col in df_ranked.columns:
        fig.add_trace(
            go.Scatter(
                x=df_ranked['weight_kg'],
                y=df_ranked[score_col],
                mode='markers',
                marker=dict(
                    size=df_ranked.get('age', [5]*len(df_ranked)) * 3,
                    color=df_ranked['rang'],
                    colorscale='RdYlBu_r',
                    showscale=True,
                    colorbar=dict(title="Rang", x=1.02)
                ),
                text=[f"{row['Nom']}<br>Poids: {row['weight_kg']:.1f}kg<br>√Çge: {row.get('age', 'N/A')}<br>Score: {row[score_col]:.3f}" 
                      for _, row in df_ranked.iterrows()],
                hovertemplate='%{text}<extra></extra>',
                name='Poids-Performance-√Çge'
            ), row=2, col=1
        )
    
    # Graphique 4: Feature importance
    if ml_results:
        # Combiner les importances de tous les mod√®les
        all_importance = {}
        for model_name, results in ml_results.items():
            if 'feature_importance' in results:
                for feature, importance in results['feature_importance'].items():
                    if feature not in all_importance:
                        all_importance[feature] = []
                    all_importance[feature].append(importance)
        
        # Moyenne des importances
        avg_importance = {k: np.mean(v) for k, v in all_importance.items()}
        top_features = dict(sorted(avg_importance.items(), key=lambda x: x[1], reverse=True)[:10])
        
        if top_features:
            fig.add_trace(
                go.Bar(
                    x=list(top_features.values()),
                    y=list(top_features.keys()),
                    orientation='h',
                    marker_color=colors[3],
                    name='Feature Importance',
                    text=[f"{v:.3f}" for v in top_features.values()],
                    textposition='auto'
                ), row=2, col=2
            )
    
    # Graphique 5: Forme vs ML
    if 'form_avg' in df_ranked.columns and score_col in df_ranked.columns:
        fig.add_trace(
            go.Scatter(
                x=df_ranked['form_avg'],
                y=df_ranked[score_col],
                mode='markers',
                marker=dict(
                    size=12,
                    color=df_ranked['odds_numeric'],
                    colorscale='Plasma',
                    showscale=True,
                    colorbar=dict(title="Cote", x=0.45, y=0.25)
                ),
                text=df_ranked['Nom'],
                name='Forme vs ML'
            ), row=3, col=1
        )
        
        # Ligne de tendance
        try:
            z = np.polyfit(df_ranked['form_avg'], df_ranked[score_col], 1)
            p = np.poly1d(z)
            fig.add_trace(
                go.Scatter(
                    x=df_ranked['form_avg'],
                    y=p(df_ranked['form_avg']),
                    mode='lines',
                    name='Tendance',
                    line=dict(color='red', dash='dash')
                ), row=3, col=1
            )
        except:
            pass
    
    # Graphique 6: Matrice de corr√©lation
    numeric_cols = ['odds_numeric', 'weight_kg', 'draw_numeric']
    if 'age' in df_ranked.columns:
        numeric_cols.append('age')
    if score_col in df_ranked.columns:
        numeric_cols.append(score_col)
    
    correlation_data = df_ranked[numeric_cols].corr()
    
    fig.add_trace(
        go.Heatmap(
            z=correlation_data.values,
            x=correlation_data.columns,
            y=correlation_data.columns,
            colorscale='RdBu',
            zmid=0,
            name='Corr√©lation',
            text=correlation_data.round(2).values,
            texttemplate='%{text}',
            textfont=dict(size=10)
        ), row=3, col=2
    )
    
    # Mise √† jour du layout
    fig.update_layout(
        height=1000,
        showlegend=True,
        title_text="üìä Dashboard ML Avanc√© - Analyse Hippique Compl√®te",
        title_x=0.5,
        title_font_size=20
    )
    
    return fig

def create_performance_dashboard(ml_results):
    """Dashboard de performance des mod√®les ML"""
    if not ml_results:
        return None
    
    # Pr√©paration des donn√©es
    models = []
    r2_scores = []
    mse_scores = []
    model_types = []
    
    for name, result in ml_results.items():
        models.append(name.upper())
        r2_scores.append(result.get('val_r2', result.get('r2', 0)))
        mse_scores.append(result.get('val_mse', result.get('mse', 0)))
        model_types.append('Ensemble' if name == 'ensemble' else 'Base')
    
    # Cr√©ation des graphiques
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('üéØ R¬≤ Score par Mod√®le', 'üìâ MSE par Mod√®le', 
                       '‚ö° Performance Comparative', 'üîÑ Cross-Validation (si disponible)'),
        specs=[[{"type": "bar"}, {"type": "bar"}],
               [{"type": "scatter"}, {"type": "box"}]]
    )
    
    colors = px.colors.qualitative.Set1
    
    # R¬≤ Scores
    fig.add_trace(
        go.Bar(
            x=models, y=r2_scores,
            marker_color=[colors[0] if t == 'Ensemble' else colors[1] for t in model_types],
            name='R¬≤ Score',
            text=[f"{score:.3f}" for score in r2_scores],
            textposition='auto'
        ), row=1, col=1
    )
    
    # MSE Scores
    fig.add_trace(
        go.Bar(
            x=models, y=mse_scores,
            marker_color=[colors[2] if t == 'Ensemble' else colors[3] for t in model_types],
            name='MSE',
            text=[f"{score:.3f}" for score in mse_scores],
            textposition='auto'
        ), row=1, col=2
    )
    
    # Performance comparative (R¬≤ vs MSE)
    fig.add_trace(
        go.Scatter(
            x=mse_scores, y=r2_scores,
            mode='markers+text',
            marker=dict(
                size=15,
                color=[colors[0] if t == 'Ensemble' else colors[4] for t in model_types],
                line=dict(width=2, color='white')
            ),
            text=models,
            textposition='middle right',
            name='R¬≤ vs MSE'
        ), row=2, col=1
    )
    
    # Cross-validation si disponible
    cv_data = []
    cv_labels = []
    for name, result in ml_results.items():
        if 'cv_r2_mean' in result:
            cv_data.append([result['cv_r2_mean'] - result['cv_r2_std'],
                           result['cv_r2_mean'],
                           result['cv_r2_mean'] + result['cv_r2_std']])
            cv_labels.append(name.upper())
    
    if cv_data:
        for i, (label, data) in enumerate(zip(cv_labels, cv_data)):
            fig.add_trace(
                go.Box(
                    y=data,
                    name=label,
                    marker_color=colors[i % len(colors)]
                ), row=2, col=2
            )
    
    fig.update_layout(
        height=800,
        title_text="üî¨ Dashboard Performance ML",
        title_x=0.5,
        showlegend=False
    )
    
    return fig

# Interface principale optimis√©e
def main():
    # En-t√™te avec animation
    st.markdown('<h1 class="main-header">üèá Analyseur Hippique IA Pro Max</h1>', unsafe_allow_html=True)
    st.markdown("*Intelligence Artificielle avanc√©e pour l'analyse pr√©dictive des courses hippiques*")
    
    # Sidebar ultra-configur√©e
    with st.sidebar:
        st.header("‚öôÔ∏è Configuration Avanc√©e")
        
        # Type de course
        race_type = st.selectbox(
            "üèÅ Type de course",
            ["AUTO", "PLAT", "ATTELE_AUTOSTART", "ATTELE_VOLTE"],
            help="AUTO = d√©tection automatique avec analyse statistique"
        )
        
        # Param√®tres ML avanc√©s
        st.subheader("ü§ñ Configuration IA")
        use_ml = st.checkbox("‚úÖ Activer pr√©dictions ML", value=True)
        ml_confidence = st.slider("üéØ Poids ML dans score final", 0.1, 0.9, 0.7, 0.05)
        
        optimize_hyperparams = st.checkbox("üîß Optimisation hyperparam√®tres", value=True)
        use_feature_selection = st.checkbox("üéØ S√©lection automatique features", value=True)
        use_ensemble = st.checkbox("üé™ Mod√®les d'ensemble", value=True)
        
        # Options d'analyse
        st.subheader("üìä Options d'Analyse")
        show_ml_dashboard = st.checkbox("üìà Dashboard ML d√©taill√©", value=True)
        show_prediction_confidence = st.checkbox("üéØ Intervalles de confiance", value=True)
        show_feature_analysis = st.checkbox("üîç Analyse features avanc√©e")
        
        # Export avanc√©
        st.subheader("üíæ Export Avanc√©")
        export_ml_report = st.checkbox("üìä Rapport ML complet")
        export_confidence_intervals = st.checkbox("üìà Intervalles de confiance")
        
        # Informations syst√®me
        st.subheader("‚ÑπÔ∏è Syst√®me IA")
        st.info("üß† **7 Mod√®les ML** + Ensemble")
        st.info("üéØ **50+ Features** automatiques")
        st.info("üìä **Optimisation** hyperparam√®tres")
        st.info("üî¨ **Validation crois√©e** int√©gr√©e")
    
    # Onglets principaux
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üåê URL Analysis", "üìÅ Upload CSV", "üß™ Test Data", 
        "üìä ML Dashboard", "üìñ Documentation"
    ])
    
    df_final = None
    
    # [Reprise du code des onglets avec les m√™mes fonctions que pr√©c√©demment mais optimis√©es]
    with tab1:
        st.subheader("üîç Analyse URL Ultra-Rapide")
        
        col1, col2 = st.columns([3, 1])
        with col1:
            url = st.text_input(
                "üåê URL de la course:",
                placeholder="https://site-courses.com/course/123",
                help="Scraping intelligent avec d√©tection automatique de structure"
            )
        with col2:
            st.markdown("<br>", unsafe_allow_html=True)
            if st.button("üöÄ Analyse Turbo", type="primary"):
                if url:
                    with st.spinner("üîÑ Extraction IA en cours..."):
                        # Utilisation de la fonction de scraping existante
                        df, message = scrape_race_data(url)
                        if df is not None:
                            st.success(f"‚úÖ **{len(df)} chevaux extraits** avec succ√®s!")
                            st.dataframe(df.head(), use_container_width=True)
                            df_final = df
                        else:
                            st.error(f"‚ùå {message}")
    
    with tab2:
        st.subheader("üì§ Upload CSV Intelligent")
        
        uploaded_file = st.file_uploader(
            "Glissez votre fichier CSV ici",
            type="csv",
            help="Format auto-d√©tect√© | Colonnes optimis√©es | Validation automatique"
        )
        
        if uploaded_file:
            try:
                df_final = pd.read_csv(uploaded_file)
                st.success(f"‚úÖ **{len(df_final)} chevaux** charg√©s avec succ√®s!")
                
                # Validation automatique intelligente
                col1, col2 = st.columns(2)
                with col1:
                    st.subheader("üìã Validation Automatique")
                    required_cols = ['Nom', 'Cote']
                    optional_cols = ['Num√©ro de corde', 'Poids', 'Musique', '√Çge/Sexe']
                    
                    for col in required_cols:
                        if col in df_final.columns:
                            st.success(f"‚úÖ {col}")
                        else:
                            st.error(f"‚ùå {col} manquant")
                    
                    for col in optional_cols:
                        if col in df_final.columns:
                            st.info(f"‚ÑπÔ∏è {col} d√©tect√©")
                
                with col2:
                    st.subheader("üìä Aper√ßu Intelligent")
                    st.dataframe(df_final.head(), use_container_width=True)
                    
            except Exception as e:
                st.error(f"‚ùå Erreur lors du chargement: {e}")
    
    with tab3:
        st.subheader("üß™ Donn√©es de Test Premium")
        
        col1, col2, col3 = st.columns(3)
        
        test_descriptions = {
            "plat": "üèÉ **Course PLAT**\n- Handicap r√©aliste\n- Cordes vari√©es\n- 8 chevaux elite",
            "attele": "üöó **Trot ATTEL√â**\n- Autostart tactique\n- Poids uniformes\n- 8 trotteurs",
            "premium": "‚≠ê **Course PREMIUM**\n- Style Arc Triomphe\n- Chevaux internationaux\n- 5 cracks mondiaux"
        }
        
        with col1:
            st.markdown(test_descriptions["plat"])
            if st.button("üèÉ Charger PLAT", use_container_width=True):
                df_final = generate_sample_data("plat")
                st.success("‚úÖ Course de PLAT charg√©e!")
        
        with col2:
            st.markdown(test_descriptions["attele"])
            if st.button("üöó Charger ATTEL√â", use_container_width=True):
                df_final = generate_sample_data("attele")
                st.success("‚úÖ Course d'ATTEL√â charg√©e!")
        
        with col3:
            st.markdown(test_descriptions["premium"])
            if st.button("‚≠ê Charger PREMIUM", use_container_width=True):
                df_final = generate_sample_data("premium")
                st.success("‚úÖ Course PREMIUM charg√©e!")
        
        if df_final is not None:
            st.markdown("### üìä Donn√©es Charg√©es")
            st.dataframe(df_final, use_container_width=True)
    
    with tab4:
        st.subheader("üìä Dashboard ML en Temps R√©el")
        st.info("üîÑ Ce dashboard se met √† jour automatiquement apr√®s chaque analyse")
        
        # Placeholder pour les m√©triques ML
        dashboard_placeholder = st.empty()
    
    with tab5:
        st.subheader("üìö Documentation IA Avanc√©e")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            ### ü§ñ Intelligence Artificielle
            
            **üß† Mod√®les Int√©gr√©s**
            - Random Forest (200 arbres)
            - Gradient Boosting (150 it√©rations)
            - Extra Trees (ensemble)
            - Ridge Regression (L2)
            - Elastic Net (L1+L2)
            - Bayesian Ridge (probabiliste)
            - Neural Network (100-50-25)
            - **Ensemble Voting** (meilleurs mod√®les)
            
            **üéØ Features Automatiques (50+)**
            - Cotes (log, inverse, sqrt, power)
            - Position (log, sqrt, percentile)
            - Poids (normalis√©, rang, vs moyenne)
            - √Çge (carr√©, optimal, interactions)
            - Forme (tendance, acc√©l√©ration, constance)
            - **Interactions polynomiales**
            - **Clustering automatique**
            - **S√©lection intelligente**
            """)
        
        with col2:
            st.markdown("""
            ### üî¨ Optimisations Avanc√©es
            
            **‚öôÔ∏è Hyperparam√®tres**
            - RandomizedSearchCV (20 it√©rations)
            - 3-fold Cross-Validation
            - Optimisation automatique
            
            **üìä Validation**
            - Train/Validation split
            - Cross-validation scores
            - Intervalles de confiance
            - Feature importance
            
            **üé™ Ensemble Learning**
            - Voting des 3 meilleurs
            - Pond√©ration dynamique
            - Pr√©dictions robustes
            
            **üìà M√©triques**
            - R¬≤ Score (coefficient d√©termination)
            - MSE (erreur quadratique)
            - MAE (erreur absolue)
            - Confiance pr√©dictions
            """)
    
    # ANALYSE PRINCIPALE ULTRA-AVANC√âE
    if df_final is not None and len(df_final) > 0:
        st.markdown("---")
        st.header("üéØ Analyse IA Ultra-Avanc√©e")
        
        # Pr√©paration des donn√©es
        df_prepared = prepare_data(df_final)
        if len(df_prepared) == 0:
            st.error("‚ùå Aucune donn√©e valide apr√®s nettoyage")
            return
        
        # D√©tection du type avec analyse pouss√©e
        if race_type == "AUTO":
            detected_type = auto_detect_race_type(df_prepared)
        else:
            detected_type = race_type
            config = ADVANCED_CONFIGS[detected_type]
            st.markdown(f'<div class="metric-card-pro">{config["description"]}</div>', 
                       unsafe_allow_html=True)
        
        # === ANALYSE ML ULTRA-AVANC√âE ===
        if use_ml:
            with st.spinner("ü§ñ IA Ultra-Avanc√©e en cours... Optimisation des mod√®les..."):
                try:
                    # Initialisation du syst√®me ML avanc√©
                    advanced_ml = AdvancedHorseRacingML()
                    
                    # Cr√©ation des features ultra-avanc√©es
                    progress_bar = st.progress(0)
                    st.text("üîß Cr√©ation des features avanc√©es...")
                    progress_bar.progress(20)
                    
                    X_advanced = advanced_ml.create_advanced_features(df_prepared, detected_type)
                    st.success(f"‚úÖ **{len(X_advanced.columns)} features** cr√©√©es automatiquement!")
                    
                    # Cr√©ation du target synth√©tique intelligent
                    st.text("üéØ G√©n√©ration du target ML intelligent...")
                    progress_bar.progress(40)
                    
                    # Target bas√© sur plusieurs facteurs
                    odds_component = 1 / (df_prepared['odds_numeric'] + 0.01)
                    if 'form_avg' in X_advanced.columns:
                        form_component = 1 / (X_advanced['form_avg'] + 1)
                    else:
                        form_component = np.ones(len(df_prepared))
                    
                    y_target = (0.6 * odds_component + 0.4 * form_component + 
                               np.random.normal(0, 0.05, len(df_prepared)))
                    
                    # Entra√Ænement des mod√®les ultra-avanc√©s
                    st.text("üöÄ Entra√Ænement des mod√®les IA...")
                    progress_bar.progress(70)
                    
                    ml_results = advanced_ml.train_advanced_models(
                        X_advanced, y_target,
                        optimize_hyperparams=optimize_hyperparams,
                        use_feature_selection=use_feature_selection
                    )
                    
                    progress_bar.progress(100)
                    st.success("‚úÖ **Syst√®me IA entra√Æn√© avec succ√®s!**")
                    
                    # S√©lection des meilleures pr√©dictions
                    best_predictions, best_model_name = advanced_ml.get_best_model_predictions(ml_results)
                    
                    if len(best_predictions) > 0:
                        # Normalisation des pr√©dictions
                        if best_predictions.max() != best_predictions.min():
                            ml_predictions_norm = ((best_predictions - best_predictions.min()) / 
                                                 (best_predictions.max() - best_predictions.min()))
                        else:
                            ml_predictions_norm = np.ones(len(best_predictions)) * 0.5
                        
                        df_prepared['ml_score'] = ml_predictions_norm
                        df_prepared['ml_confidence'] = ml_results.get(best_model_name, {}).get('prediction_confidence', [0.5] * len(df_prepared))
                        
                        # Affichage du rapport ML
                        st.subheader("ü§ñ Rapport ML D√©taill√©")
                        report = advanced_ml.generate_prediction_report(ml_results)
                        st.markdown(report)
                        
                except Exception as e:
                    st.error(f"‚ùå Erreur dans l'analyse ML avanc√©e: {str(e)}")
                    use_ml = False
                    ml_results = {}
        
        # === CALCUL DU SCORE FINAL OPTIMIS√â ===
        # Score traditionnel am√©lior√©
        traditional_components = []
        
        # Composant cotes (toujours pr√©sent)
        odds_score = 1 / (df_prepared['odds_numeric'] + 0.01)
        traditional_components.append(('odds', odds_score, 0.4))
        
        # Composant position (si pertinent)
        if detected_type in ['PLAT', 'ATTELE_AUTOSTART']:
            config = ADVANCED_CONFIGS[detected_type]
            draw_score = np.zeros(len(df_prepared))
            for i, draw in enumerate(df_prepared['draw_numeric']):
                if draw in config['optimal_draws']:
                    draw_score[i] = 1.0
                elif detected_type == 'PLAT' and draw <= 4:
                    draw_score[i] = 0.8
                elif detected_type == 'ATTELE_AUTOSTART' and draw <= 9:
                    draw_score[i] = 0.6
                else:
                    draw_score[i] = 0.3
            traditional_components.append(('draw', draw_score, 0.3))
        
        # Composant poids (si important)
        if ADVANCED_CONFIGS[detected_type]['weight_importance'] > 0.1:
            weight_score = 1 / (df_prepared['weight_kg'] - df_prepared['weight_kg'].min() + 1)
            traditional_components.append(('weight', weight_score, 0.3))
        
        # Combinaison des composants traditionnels
        traditional_score = np.zeros(len(df_prepared))
        total_weight = sum(weight for _, _, weight in traditional_components)
        
        for name, score, weight in traditional_components:
            normalized_score = (score - score.min()) / (score.max() - score.min() + 1e-8)
            traditional_score += normalized_score * (weight / total_weight)
        
        # Score final combin√©
        if use_ml and 'ml_score' in df_prepared.columns:
            df_prepared['score_final'] = (
                (1 - ml_confidence) * traditional_score + 
                ml_confidence * df_prepared['ml_score']
            )
            df_prepared['prediction_method'] = f"Hybride (ML: {ml_confidence:.0%})"
        else:
            df_prepared['score_final'] = traditional_score
            df_prepared['prediction_method'] = "Traditionnel"
        
        # === CLASSEMENT FINAL ===
        df_ranked = df_prepared.sort_values('score_final', ascending=False).reset_index(drop=True)
        df_ranked['rang'] = range(1, len(df_ranked) + 1)
        
        # Ajout de classes de confiance
        if 'ml_confidence' in df_ranked.columns:
            df_ranked['confidence_class'] = pd.cut(
                df_ranked['ml_confidence'], 
                bins=[0, 0.3, 0.7, 1.0], 
                labels=['Faible', 'Moyenne', '√âlev√©e']
            )
        
        # === AFFICHAGE DES R√âSULTATS ULTRA-AVANC√âS ===
        col1, col2 = st.columns([2.5, 1.5])
        
        with col1:
            st.subheader("üèÜ Classement Final IA")
            
            # Pr√©paration de l'affichage
            display_cols = ['rang', 'Nom', 'Cote', 'Num√©ro de corde']
            if 'Poids' in df_ranked.columns:
                display_cols.append('Poids')
            display_cols.extend(['score_final', 'prediction_method'])
            
            if 'ml_confidence' in df_ranked.columns:
                display_cols.append('confidence_class')
            
            # Formatage avanc√©
            display_df = df_ranked[display_cols].copy()
            display_df['Score IA'] = display_df['score_final'].round(3)
            display_df['M√©thode'] = display_df['prediction_method']
            
            # Suppression des colonnes techniques
            display_df = display_df.drop(['score_final', 'prediction_method'], axis=1)
            
            # Styling conditionnel
            def style_confidence(val):
                if val == '√âlev√©e':
                    return 'background-color: #d1fae5; color: #065f46'
                elif val == 'Moyenne':
                    return 'background-color: #fef3c7; color: #92400e'
                else:
                    return 'background-color: #fecaca; color: #991b1b'
            
            if 'confidence_class' in display_df.columns:
                styled_df = display_df.style.applymap(
                    style_confidence, subset=['confidence_class']
                ).background_gradient(
                    subset=['Score IA'], cmap='RdYlGn'
                )
            else:
                styled_df = display_df.style.background_gradient(
                    subset=['Score IA'], cmap='RdYlGn'
                )
            
            st.dataframe(styled_df, use_container_width=True)
        
        with col2:
            st.subheader("üìä M√©triques Avanc√©es")
            
            # M√©triques ML si disponibles
            if use_ml and ml_results:
                best_model_result = ml_results.get(best_model_name, {})
                
                if 'val_r2' in best_model_result:
                    r2_score = best_model_result['val_r2']
                    confidence_color = "ml-confidence-high" if r2_score > 0.7 else "ml-confidence-medium" if r2_score > 0.4 else "ml-confidence-low"
                    st.markdown(f'<div class="metric-card-pro">üß† R¬≤ Score ML<br><strong>{r2_score:.3f}</strong></div>', 
                               unsafe_allow_html=True)
                
                if 'cv_r2_mean' in best_model_result:
                    cv_score = best_model_result['cv_r2_mean']
                    cv_std = best_model_result['cv_r2_std']
                    st.markdown(f'<div class="metric-card-pro">üîÑ Cross-Validation<br><strong>{cv_score:.3f}¬±{cv_std:.3f}</strong></div>', 
                               unsafe_allow_html=True)
                
                st.markdown(f'<div class="metric-card-pro">üèÜ Meilleur Mod√®le<br><strong>{best_model_name.upper()}</strong></div>', 
                           unsafe_allow_html=True)
            
            # M√©triques de course
            favoris = len(df_ranked[df_ranked['odds_numeric'] < 5])
            outsiders = len(df_ranked[df_ranked['odds_numeric'] > 15])
            
            st.markdown(f'<div class="metric-card-pro">‚≠ê Favoris (cote < 5)<br><strong>{favoris}</strong></div>', 
                       unsafe_allow_html=True)
            st.markdown(f'<div class="metric-card-pro">üé≤ Outsiders (cote > 15)<br><strong>{outsiders}</strong></div>', 
                       unsafe_allow_html=True)
            
            # R√©partition des confiances
            if 'confidence_class' in df_ranked.columns:
                conf_counts = df_ranked['confidence_class'].value_counts()
                st.markdown("### üéØ R√©partition Confiance")
                for conf_level, count in conf_counts.items():
                    conf_class = f"ml-confidence-{conf_level.lower()}" if conf_level != 'Moyenne' else "ml-confidence-medium"
                    st.markdown(f'<div class="prediction-box-pro {conf_class}"><strong>{conf_level}</strong>: {count} chevaux</div>', 
                               unsafe_allow_html=True)
            
            # Top 3 avec analyse d√©taill√©e
            st.subheader("ü•á Top 3 IA")
            for i in range(min(3, len(df_ranked))):
                horse = df_ranked.iloc[i]
                
                # Classe de confiance pour le styling
                if 'ml_confidence' in horse:
                    conf_val = horse['ml_confidence']
                    if conf_val > 0.7:
                        conf_class = "ml-confidence-high"
                        conf_icon = "üü¢"
                    elif conf_val > 0.4:
                        conf_class = "ml-confidence-medium" 
                        conf_icon = "üü°"
                    else:
                        conf_class = "ml-confidence-low"
                        conf_icon = "üî¥"
                    
                    confidence_info = f"{conf_icon} Confiance: {conf_val:.2f}"
                else:
                    conf_class = "ml-confidence-medium"
                    confidence_info = ""
                
                st.markdown(f"""
                <div class="prediction-box-pro {conf_class}">
                    <strong>{i+1}. {horse['Nom']}</strong><br>
                    üéØ Cote: {horse['Cote']} | üìä Score IA: {horse['score_final']:.3f}<br>
                    üìç Position: {horse['Num√©ro de corde']} | ‚öñÔ∏è Poids: {horse.get('Poids', 'N/A')}<br>
                    {confidence_info}
                </div>
                """, unsafe_allow_html=True)
        
        # === VISUALISATIONS ULTRA-AVANC√âES ===
        st.subheader("üìä Visualisations IA Avanc√©es")
        
        prediction_confidence = df_ranked.get('ml_confidence', None)
        fig_advanced = create_advanced_visualizations(
            df_ranked, 
            ml_results if use_ml else None,
            prediction_confidence
        )
        st.plotly_chart(fig_advanced, use_container_width=True)
        
        # Dashboard ML si activ√©
        if show_ml_dashboard and use_ml and ml_results:
            st.subheader("üî¨ Dashboard Performance ML")
            fig_dashboard = create_performance_dashboard(ml_results)
            if fig_dashboard:
                st.plotly_chart(fig_dashboard, use_container_width=True)
        
        # === ANALYSE DES FEATURES SI DEMAND√âE ===
        if show_feature_analysis and use_ml and hasattr(advanced_ml, 'feature_importance'):
            st.subheader("üîç Analyse Avanc√©e des Features")
            
            # Combinaison des importances de tous les mod√®les
            all_features = {}
            for model_name, importance_dict in advanced_ml.feature_importance.items():
                for feature, importance in importance_dict.items():
                    if feature not in all_features:
                        all_features[feature] = []
                    all_features[feature].append(importance)
            
            # Calcul des statistiques par feature
            feature_stats = []
            for feature, importances in all_features.items():
                feature_stats.append({
                    'Feature': feature,
                    'Importance Moyenne': np.mean(importances),
                    '√âcart-Type': np.std(importances),
                    'Min': np.min(importances),
                    'Max': np.max(importances),
                    'Nb Mod√®les': len(importances)
                })
            
            feature_df = pd.DataFrame(feature_stats).sort_values('Importance Moyenne', ascending=False)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("### üèÜ Top 15 Features")
                st.dataframe(feature_df.head(15), use_container_width=True)
            
            with col2:
                st.markdown("### üìä Distribution des Importances")
                fig_features = px.box(
                    feature_df.head(10), 
                    y='Feature', 
                    x='Importance Moyenne',
                    title="Distribution des Importances (Top 10)"
                )
                st.plotly_chart(fig_features, use_container_width=True)
        
        # === EXPORT AVANC√â ===
        st.subheader("üíæ Export Ultra-Complet")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # Export CSV enrichi
            export_df = df_ranked.copy()
            if use_ml:
                export_df['ml_model_used'] = best_model_name
                if 'ml_confidence' in export_df.columns:
                    export_df['prediction_confidence'] = export_df['ml_confidence']
            
            csv_data = export_df.to_csv(index=False, encoding='utf-8')
            st.download_button(
                label="üìÑ CSV Enrichi",
                data=csv_data,
                file_name=f"pronostic_ia_avance_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
        
        with col2:
            # Export JSON complet
            export_data = {
                'metadata': {
                    'timestamp': datetime.now().isoformat(),
                    'race_type_detected': detected_type,
                    'num_horses': len(df_ranked),
                    'ml_enabled': use_ml,
                    'best_ml_model': best_model_name if use_ml else None,
                    'features_count': len(X_advanced.columns) if use_ml else 0
                },
                'predictions': df_ranked.to_dict('records'),
                'ml_performance': ml_results if use_ml else {},
                'feature_importance': advanced_ml.feature_importance if use_ml else {}
            }
            
            json_data = json.dumps(export_data, indent=2, ensure_ascii=False, default=str)
            st.download_button(
                label="üìã JSON Complet",
                data=json_data,
                file_name=f"analyse_complete_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
        
        with col3:
            # Rapport ML d√©taill√©
            if export_ml_report and use_ml:
                ml_report = {
                    'executive_summary': {
                        'best_model': best_model_name,
                        'r2_score': ml_results.get(best_model_name, {}).get('val_r2', 'N/A'),
                        'top_features': list(advanced_ml.feature_importance.get(best_model_name, {}).keys())[:5],
                        'confidence_distribution': df_ranked['confidence_class'].value_counts().to_dict() if 'confidence_class' in df_ranked.columns else {}
                    },
                    'detailed_results': ml_results,
                    'model_comparison': {name: result.get('val_r2', result.get('r2', 0)) for name, result in ml_results.items()},
                    'recommendations': advanced_ml.generate_prediction_report(ml_results)
                }
                
                report_json = json.dumps(ml_report, indent=2, ensure_ascii=False, default=str)
                st.download_button(
                    label="üìä Rapport ML",
                    data=report_json,
                    file_name=f"rapport_ml_detaille_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json"
                )

# Point d'entr√©e avec gestion d'erreurs avanc√©e
if __name__ == "__main__":
    try:
        main()
